#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass ctex-article
\begin_preamble
\usepackage{amsmath}
\usepackage{bm}
\usepackage{ctex}

\usepackage{color}
\usepackage{fancyvrb}
\usepackage{CJKutf8}
\usepackage[overlap, CJK]{ruby}
\newenvironment{SChinese}{%
\CJKfamily{gbsn}%
\CJKtilde
\CJKnospace}{}
\newcommand{\cntxt}[1]{\begin{CJK}{UTF8}{}\begin{SChinese}#1\end{SChinese}\end{CJK}}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
% set default figure placement to htbp
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language chinese-simplified
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\font_cjk gbsn
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
用Pointer Network网络模型给数字排序
\end_layout

\begin_layout Author
Linyang He
\end_layout

\begin_layout Standard
本文以为数字（包括整数、浮点数）情景为例，重点关注了Pointer Network模型作为一个attention机制特例的应用。本文先会讲述attention模
型，再描述了Pointer Ntework。接着展示在长度分别为5、10的整数和长度为5的浮点数上排序结果的展示。最后是实验的总结，并提出了一些自己的思考。
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
Attention机制
\end_layout

\begin_layout Standard
基于Attention机制（注意力机制）神经网络是最近神经网络研究的一个热点。通常而言，Attention模型利用在seq2seq上。
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename pasted1.png
	scale 70

\end_inset


\end_layout

\begin_layout Standard
最基本的seq2seq模型包含一个encoder和一个decoder，一般的做法是将一个输入的句子编码成一个固定大小的state，然后作为decoder的初始状
态（当然也可以作为每一时刻的输入），但这样的一个状态对于decoder中的所有时刻都是一样的。 Attention即为注意力，人脑在对于的不同部分的注意力是不同
的。没有attention机制的encoder-decoder结构通常把encoder的最后一个状态作为decoder的输入（可能作为初始化，也可能作为每一时刻
的输入），但是encoder的state毕竟是有限的，存储不了太多的信息，对于decoder过程，每一个步骤都和之前的输入都没有关系了，只与这个传入的state
有关。attention机制的引入之后，decoder根据时刻的不同，让每一时刻的输入都有所不同。对于不同的decoder阶段，输入的hidden_state也
发生了变化，而不是仅仅一个c作为decoder的输入了。
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename pasted4.png
	scale 30

\end_inset


\end_layout

\begin_layout Standard
Attention-based Model其实就是一个相似性的度量，当前的输入与目标状态越相似，那么在当前的输入的权重就会越大，说明当前的输出越依赖于当前的输入
。
\end_layout

\begin_layout Standard
假设我们对encoder端的state标注为：
\begin_inset Formula $(h_{1},...,h_{T_{A}})$
\end_inset

， 而decoder端的state标注为：
\begin_inset Formula $(d_{1},...,d_{T_{B}})$
\end_inset

, 那么为了计算 在decoder端第t个时刻的attention 向量, 我们可以根据如下公式：
\end_layout

\begin_layout Standard
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout

$$s^t_i = v^T tanh(W_1h_i + W_2d_t)$$
\end_layout

\begin_layout Plain Layout

$$a^t_i = softmax(s^t_i )$$
\end_layout

\begin_layout Plain Layout

$$c_t = 
\backslash
sum^{T_A}_{i=1} a^t_ih_i$$
\end_layout

\end_inset

这里的
\begin_inset Formula $W_{1},$
\end_inset


\begin_inset Formula $W_{2}$
\end_inset

, 
\begin_inset Formula $v^{T}$
\end_inset

都是通过网络学习得来的参数。训练好这个含有attention机制的seq2seq网络之后，如果
\begin_inset ERT
status open

\begin_layout Plain Layout

$a_i^T$
\end_layout

\end_inset

越高，他们对相应的注意力就应该越高。
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename pasted3.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
如图，以机器翻译（Neural Translation Machine)为例，attention值被可视化了，如果越接近白色，则说明decoder端另外一门语言
的某些词语和encoder端源语言的对应的词越被“注意”。这说明了attention机制，确确实实起到了特别关注序列中某个对象。
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename pasted2.png
	scale 60

\end_inset


\end_layout

\begin_layout Subsection
Pointer Network与数字排序任务
\end_layout

\begin_layout Standard
考虑到普通attention机制的seq2seq不能处理变长的问题，且如果出现一个词典中不存在的词，普通attention也无能为力解决。这时候就需要一个可以处
理变长和处理词典中不存在的token的网络， Pointer Network就诞生了。Pointer Network 实际上是一种特殊的注意力机制。我们知道，事
实上，注意力机制可以分为两步：一是计算注意力分布
\begin_inset Formula $α$
\end_inset

，二是根据
\begin_inset Formula $α$
\end_inset

 来计算输入信息的加权平均。我们可以只利用注意力机制中的第一步，将注意 力分布作为一个软性的指针（pointer）来指出相关信息的位置。
\series bold
直观而言，是把普通的attention model中的加权平均变成了取最大值
\series default
。针网络（Pointer Network）[Vinyals et al., 2015]是一种序列到序列模型， 输入是长度为n的向量序列
\begin_inset ERT
status open

\begin_layout Plain Layout

$X = x_1 ,··· ,x_n$
\end_layout

\end_inset

 ，输出是下标序列
\begin_inset ERT
status open

\begin_layout Plain Layout

$c_{1:m} = c_1 ,c_2 ,··· ,c_m ， c_i 
\backslash
in [1,n],∀i$
\end_layout

\end_inset

。 和一般的序列到序列任务不同，这里的输出序列是输入序列的下标（索引）。 数字排序任务是指，输入一组乱序的数字，要按照规定的某个顺序进行对下标的排序，比如输
 入为20,5,10，输出为1,3,2。这里的数字可以是整数，也可以是浮点数。本文也正是探讨这样的应用。条件概率可以写成
\begin_inset ERT
status open

\begin_layout Plain Layout

$$p(c_{1:m} |X{1:n} ) 
\backslash
approx  
\backslash
Pi_{i=1}^mp(c_i|X_{c_1},..,X_{c_{i-1}},X_{1:n})$$
\end_layout

\end_inset


\end_layout

\begin_layout Standard
公式中的条件概率可以看成注意力分布来计算。假设用一个循环神经网络对
\begin_inset ERT
status open

\begin_layout Plain Layout

$x_{c1} ,··· ,x_{c_{i−1}} ,x_{1:n}$ 
\end_layout

\end_inset

进行编码得到向量
\begin_inset ERT
status open

\begin_layout Plain Layout

$h_i$
\end_layout

\end_inset

 ，则 
\begin_inset ERT
status open

\begin_layout Plain Layout

$$p(c_i |c_{1:i−1} ,x_{1:n} ) = softmax(s_i,j )$$
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

$s_{i,j}$
\end_layout

\end_inset

其实就是上文普通attention机制中的
\begin_inset ERT
status open

\begin_layout Plain Layout

$s^t_i$
\end_layout

\end_inset

。
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename pasted5.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
如图，我们通过左边的编码器得到了h3作为hidden_state输入到解码器中。此时，我们在根据attention分布指向了概率最大的那个位置。而我们的数据集是
已知这个位置信息的，这样通过位置的概率分布和真实的位置信息，通过计算CrossEntropy就可以得到loss并实现反向传播了。
\end_layout

\begin_layout Section
Experiment
\end_layout

\begin_layout Standard
笔者在分析了提供的样例代码之后，认为样例代码的数据处理操作并不符合一般的流程规范。比如，为何在一个epoch里面才调用生成数据，这样不就意味着，每一个epoch
都只有一个batch么，这相当于在当前迭代中遍历整个训练集，这样的操作就失去了mini-batch梯度下降的可能性，代码的泛化能力较差，更何况我们知道通常情况下
，效果最好的就是mini batch。为了解决这个问题，让mini-batch算法能够真正被使用，笔者并未采用样例代码的框架。
\end_layout

\begin_layout Subsection
Dataset
\end_layout

\begin_layout Standard
可以看到，样例代码中已经提供了生成数据的函数，只需要调用即可。不同的是，笔者选择在训练前就构造好数据集。
\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Standard
pointer work基本上分为了三个部分。一个encoder，一个decoder，和一个用来attention的部分。
\end_layout

\begin_layout Subsubsection
Encoder
\end_layout

\begin_layout Standard
这部分并不受其他部分影响。于是我们可以用一个普通的LSTM或者GRU网络作为encoder即可。注意LSTM和GRU的输出长度不同。LSTM有两个hidden_
state门控输出。
\end_layout

\begin_layout Subsubsection
Decoder
\end_layout

\begin_layout Standard
因为我们知道decoder端受到encoder端每个时序上的输入影响，因此，我们使用LSTMCell或者GRUCell在for循环中构造网络，而不是直接用一个L
STM或者GRU网络。
\end_layout

\begin_layout Subsubsection
Attention
\end_layout

\begin_layout Standard
Attention关注的是在1.2中公式的实现。我们可以用线性层来实现。其实这相当于在当前时刻的decoder的hidden_state和全面全部时刻encode
r的hidden_state上面又添加了个全连接层，并通过softmax归一化之后，得到了概率分布。这个概率分布可以和标注好的Y进行crossentropy计算
。
\end_layout

\begin_layout Subsection
Training
\end_layout

\begin_layout Standard
定义超参数如下，
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
超参数
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
值
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
解释
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
EPOCH
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
400
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
训练多少代
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Learning_rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.001
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
学习率
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
total_size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
数据集大小
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
batch_size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
250
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
batch大小为250，一个epoch有40个batch
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
input_size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
输入数据的维度
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
weight_size 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
256
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
attention中用得到的全连接层的节点个数
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
hidden_size
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
512
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RNN中的隐藏层的结点个数
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
模型采用AdaM优化，crossentropy作为loss function。
\end_layout

\begin_layout Subsection
Test
\end_layout

\begin_layout Standard
模型训练好后，另取数据进行测试。
\end_layout

\begin_layout Section
Result
\end_layout

\begin_layout Standard
本次实验中，我们训练了三个模型，情况如下，其中trraning_loss是最后一次迭代的值。正整数排序：
\end_layout

\begin_layout Standard
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Task
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Int, 5 bit
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Int, 10 bit
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LSTM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GRU
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LSTM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GRU
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Train Loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00136
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00020
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01336
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00007
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Train Acc
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.74%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.94%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
98.48% 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.36%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Test Acc
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
96.70%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
97.20%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
91.30%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
75.50%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
浮点数排序：
\end_layout

\begin_layout Standard
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Task
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Float, 5 bit
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Float, 10 bit
\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LSTM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GRU
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LSTM
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
GRU
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Train Loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00078
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00118
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00872
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.00753
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Train Acc
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.60%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.66%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.51%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
99.81%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Test Acc
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
87.10%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
 91.80%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
53.20%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
64.40%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
结果分析：
\end_layout

\begin_layout Enumerate
我们发现，对于正整数而言，随着要求排序的序列长度变长，GRU的稳定性下滑很严重。这更加说明了LSTM确实可以解决长短依赖问题。
\end_layout

\begin_layout Enumerate
在排序序列比较短的时候，GRU的表现更优异。考虑到GRU的门控相较LSTM要少一个，在序列较短的时候，处理的效能会更高。
\end_layout

\begin_layout Enumerate
对于浮点数排序，当序列长的时候，GRU和LSTM的表现都比较糟糕。说明pointer network算法本身更适合处理离散型的数据。
\end_layout

\begin_layout Enumerate
总体而言，在不知道数据类型的时候，短序列用GRU，长序列用LSTM是不错的选择。
\end_layout

\begin_layout Section
Others
\end_layout

\begin_layout Standard
对数字排序生成这个任务的一些思考：
\end_layout

\begin_layout Enumerate
我们发现，在训练和测试的时候，实际采用的都是同样长度的数字序列。但是我们知道seq2seq model是可以处理变长问题的，如果测试的时候采用的是更长的数字序列
，结果又会如何呢。
\end_layout

\begin_layout Enumerate
实际上，普通的attention model已经可以对定长度的整数序列排序很好的work，但是如果是浮点数，我们会发现，不可能让测试集中的每一个数据都出在训练集
中，这种情况下，普通attention模型就失效了。从这种角度而言，pointer network有点像一个复制粘贴的网络，根据需要把输入中的元素挑选出来按照一
定顺序排列。而这也是为什么pointer network适合用在文本摘要的任务上。把一段文字的一些词语挑选出来拼起来就可以成为其摘要。
\end_layout

\end_body
\end_document
