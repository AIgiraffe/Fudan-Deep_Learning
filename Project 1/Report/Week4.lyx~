#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass ctex-article
\begin_preamble
\usepackage{amsmath}
\usepackage{bm}
\usepackage{ctex}

\usepackage{color}
\usepackage{fancyvrb}
\usepackage{CJKutf8}
\usepackage[overlap, CJK]{ruby}
\newenvironment{SChinese}{%
\CJKfamily{gbsn}%
\CJKtilde
\CJKnospace}{}
\newcommand{\cntxt}[1]{\begin{CJK}{UTF8}{}\begin{SChinese}#1\end{SChinese}\end{CJK}}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
% set default figure placement to htbp
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language chinese-simplified
\language_package default
\inputencoding utf8-plain
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\font_cjk gbsn
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Project 1 of NNDL
\end_layout

\begin_layout Author
Linyang He (15307130240)
\end_layout

\begin_layout Section
问题
\end_layout

\begin_layout Standard
理论和实验证明,一个两层的ReLU网络可以模拟任何函数.请自行定义一个函数, 并使用基于ReLU的神经网络来拟合此函数.
\end_layout

\begin_layout Section
证明
\end_layout

\begin_layout Standard
问题中的描述并不准确.首先,“模拟”一词含义也不清晰,笔者默认为问题的意思是“拟合”.此外,一个两层的ReLU网络并不能“模拟”任何函数.
 根据Hornik et al., 1989, 我们注意到原文中提到：“This paper rigorously establishes that
 standard multilayer feedforward networks with as few as one hidden layer
 using using arbitrary squashing functions are capable of approximating
 any 
\series bold
Borel measurable
\series default
 function from one finite dimensional space to another to any desired degree
 of accuracy, provided sufficiently many hidden units are available.” 可见并不是所有的函数都
是可以approximate的,而只是对博雷尔可测（Borel measurable）函数.于是我们将问题修改为：
\series bold
一个两层的ReLU网络可以拟合任何博雷尔可测函数
\series default
.
\end_layout

\begin_layout Standard
根据Universal Approximator Theorem,我们有：
\end_layout

\begin_layout Description
定理 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
varphi(
\backslash
cdot)$
\end_layout

\end_inset

是一个有界且连续的单调上升函数,且
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
varphi(
\backslash
cdot)$
\end_layout

\end_inset

不恒为常数,令 
\begin_inset Formula $I_{m}$
\end_inset

 是 
\begin_inset ERT
status open

\begin_layout Plain Layout

$R^m$
\end_layout

\end_inset

 的一个紧子集,那么
\begin_inset ERT
status open

\begin_layout Plain Layout

 $
\backslash
forall 
\backslash
varepsilon>0, f 
\backslash
in C(I_m), 
\backslash
exists N 
\backslash
in N,v_i, b_i 
\backslash
in R, w_i 
\backslash
in  R^m,(i=1,2,...,N)$
\end_layout

\end_inset

, 使得可以定义
\begin_inset ERT
status open

\begin_layout Plain Layout

 $F(x)=
\backslash
sum_{i=1}^{N}v_i
\backslash
varphi(w_i^Tx + b_i)$
\end_layout

\end_inset

 , 满足 
\begin_inset ERT
status open

\begin_layout Plain Layout

$|F(x)-f(x)|<
\backslash
varepsilon$
\end_layout

\end_inset

 对
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
forall x 
\backslash
in I_m$
\end_layout

\end_inset

 成立.
\end_layout

\begin_layout Standard
注意到对于单独的一层ReLU网络,ReLU函数并不满足
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
varphi(
\backslash
cdot)$
\end_layout

\end_inset

是一个有界且连续的单调上升函数的条件.于是,对于ReLU网络,我们可以构造：
\begin_inset ERT
status open

\begin_layout Plain Layout

$$ 
\backslash
varphi '(x)=ReLU(x-a)-ReLU(x-b),(a < b)$$
\end_layout

\end_inset

 可以发现
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
mathop{
\backslash
varphi '(x)}
\backslash
limits_{x
\backslash
to-
\backslash
infty} = 0,    
\backslash
mathop{
\backslash
varphi '(x)}
\backslash
limits_{x
\backslash
to+
\backslash
infty}= 
\backslash
mathop{lim}
\backslash
limits_{x
\backslash
to+
\backslash
infty}   [(x-a) - (x-b)] = b-a .$
\end_layout

\end_inset

此时, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
varphi'$
\end_layout

\end_inset

有界、连续且单调,满足Universal Approximator Theorem.于是我们可以定义：
\begin_inset ERT
status open

\begin_layout Plain Layout

 $F(x)=
\backslash
sum_{i=1}^{N}v_i
\backslash
varphi'(w_i^Tx + b_i)$
\end_layout

\end_inset

 , 满足 
\begin_inset ERT
status open

\begin_layout Plain Layout

$|F(x)-f(x)|<
\backslash
varepsilon$
\end_layout

\end_inset

 对
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
forall x 
\backslash
in I_m$
\end_layout

\end_inset

 成立.
 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
varphi'$
\end_layout

\end_inset

是两个ReLU函数的线性组合,可以通过两层的ReLU网络构造,这样就证明了
\series bold
一个两层的ReLU网络可以拟合任何博雷尔可测函数
\series default
.
 
\end_layout

\begin_layout Section
实现
\end_layout

\begin_layout Standard
我们先以一个简单的函数为例说明实现过程，之后我们会比较不同的函数拟合之间的比较。
\end_layout

\begin_layout Subsection
函数定义
\end_layout

\begin_layout Standard
我们以一个实际的一元二次函数为例子.
\begin_inset ERT
status open

\begin_layout Plain Layout

$$y = 2x^2 + 3x,x 
\backslash
in R$$
\end_layout

\end_inset

在构建函数的时候,我们可以用[-10,10]上的均匀分布的500个点来表示.同时这也是我们的训练集.对于测试集,我们另取[-10,10]上随机分布的100个点.
\end_layout

\begin_layout Subsection
模型表述
\end_layout

\begin_layout Standard
对于神经网络模型,我们构造了两层hidden layer激活函数均是ReLU的网络.输入层1个节点（x）,第一层隐藏层5个节点,第二层隐藏层10个节点,输出层1个
节点（y）.此外,对于网络的optimizer,我们选用了随机梯度下降（SGD）,learning rate为0.0001.
 损失函数选取的是均方差MSE.神经网络下图所示.
\end_layout

\begin_layout Subsection
拟合效果
\end_layout

\begin_layout Standard
对于训练好的网络，我们发现，对于测试集相对误差（下文会提到）Relative error为9.95e-07.而对于测试集Relative error是4.79e-06.
 神经网络在测试集表现地非常好，从数据和图中都可以看出,神经网络确实很好的拟合了
\begin_inset ERT
status open

\begin_layout Plain Layout

$y = 2x^2 + 3x$
\end_layout

\end_inset

这个函数.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename fig.png
	scale 65

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename fig1.png
	scale 45

\end_inset


\end_layout

\begin_layout Subsection
实验分析
\end_layout

\begin_layout Subsubsection
对于实验细节的讨论
\end_layout

\begin_layout Standard
对于隐藏层结点个书的选择，我们根据经验公式：
\begin_inset ERT
status open

\begin_layout Plain Layout

$$h = 
\backslash
sqrt{m+n} + a$$
\end_layout

\end_inset

这里，h为隐藏层节点个数，m为输入层节点个数，n为输出层节点个数，a为1-10的常数。这样，我们的10和5的节点数是较为合理的。
\end_layout

\begin_layout Standard
在训练中，为了提升训练速度，我们希望在loss值变化非常小的时候（意味着几乎到达了最优点），能够提早结束训练。考虑到归一化的原因，我们定义相对误差(Relati
ve Error)为：
\begin_inset ERT
status open

\begin_layout Plain Layout

$$RelError = 
\backslash
dfrac{MSE}{||y||^2} = 
\backslash
dfrac{
\backslash
frac{1}{n}
\backslash
sum_{i=1}(y_i−
\backslash
hat{y_i})2}{||y||^2}$$
\end_layout

\end_inset

且规定当相对误差小于1e-6的时候，训练提早结束。实验发现，对于原本20000步epochs的训练，可以在第10356次迭代时后结束训练，极大地提升了神经网络的
效率。
\end_layout

\begin_layout Subsubsection
拟合不同类型函数之间的比较
\end_layout

\begin_layout Standard
为了便于比较，我们设定训练集都是500个点。
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
函数类型
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
函数举例
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
迭代次数
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
测试集相对误差
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
多项式
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y=2x^{2}+3x\text{, }x\in[-10,10]$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10356
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4.79e-06
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
三角函数
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y=sin(x),x\in[-3,3]$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
500000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.13e-05
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
指数函数
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y=e^{x},x\in[-1,6]$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
30276
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4.54e-06
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
对数函数
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y=lnx,x\in(0,1]$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
500000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.89e-05
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

我们发现，三角函数比较难学习的，迭代次数高达500000后测试集相对误差仍然高。主要的原因是在所取的定义域上，三角函数形状较为复杂。而对数函数较难以拟合的部分主
要是接近在
\begin_inset ERT
status open

\begin_layout Plain Layout

$x
\backslash
to0$
\end_layout

\end_inset

时，
\begin_inset ERT
status open

\begin_layout Plain Layout

$y
\backslash
to-
\backslash
infty$
\end_layout

\end_inset

的时候，此时loss总会很大。当然，我们也可以预见，对于高次、图像复杂的多项式函数，神经网络拟合也较为困难。下图是一些神经网络拟合函数的图示。注意在Python
代码中，默认以多项式函数为主。
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename fig3.png
	scale 50

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename fig4.png
	scale 50

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename fig5.png
	scale 50

\end_inset


\end_layout

\end_body
\end_document
